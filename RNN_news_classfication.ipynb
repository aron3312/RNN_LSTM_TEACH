{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用RNN來進行文本分類作業\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料準備訓練資料，並且建立文字、預測類別數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2892\n",
      "722\n",
      "2916\n",
      "['politics', 'society', 'business', 'sports']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import string\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler =pickle.load(open('train.pkl','rb'))\n",
    "valid_sampler = pickle.load(open('valid.pkl','rb'))\n",
    "dataset = train_sampler+valid_sampler\n",
    "print(len(train_sampler))\n",
    "print(len(valid_sampler))\n",
    "#建立文字列表\n",
    "all_chars = list(set([d for p in dataset for d in p[1]]))\n",
    "\n",
    "#總共出現的字數量\n",
    "print(len(all_chars))\n",
    "\n",
    "n_chars = len(all_chars)\n",
    "\n",
    "all_categories = list(set([p[0] for p in dataset]))\n",
    "n_categories = len(all_categories)\n",
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將文字轉成數值並且轉換成Tensor格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([6, 1, 2916])\n",
      "tensor([[1528],\n",
      "        [ 144],\n",
      "        [1568],\n",
      "        [2681]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 從列表中找到文字代表的數字\n",
    "def charToIndex(char):\n",
    "    return all_chars.index(char)\n",
    "\n",
    "# 從文字到數值tensor\n",
    "def charToTensor(char):\n",
    "    tensor = torch.zeros(1, n_chars)\n",
    "    tensor[0][charToIndex(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "#將整列轉換成數值tensor\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_chars)\n",
    "    for li, char in enumerate(line):\n",
    "        tensor[li][0][charToIndex(char)] = 1\n",
    "    return tensor\n",
    "def linetoindexTensor(line):\n",
    "    tensor = torch.zeros(len(line),1,dtype=torch.long)\n",
    "    for i in range(0,len(line)):\n",
    "        tensor[i][0] = charToIndex(line[i])\n",
    "    return tensor\n",
    "\n",
    "print(charToTensor('今'))\n",
    "\n",
    "print(lineToTensor('今天真的好棒').size())\n",
    "\n",
    "print(linetoindexTensor('今天真棒'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,use_embedding):\n",
    "        super(RNN, self).__init__()\n",
    "#         embedding_dim = 300\n",
    "#         self.word_embeddings = nn.Embedding(input_size, embedding_dim)\n",
    "#         self.use_embedding = use_embedding\n",
    "#         if self.use_embedding :\n",
    "#             input_size = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        #activation\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        #activation\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        #activation\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #concat input and last hidden(上一個的預測以及這一個的input)\n",
    "#         if self.use_embedding:\n",
    "#             input =  self.word_embeddings(input)\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        #fully connected to hidden \n",
    "        hidden = self.i2h(combined)\n",
    "        #Connected to tag\n",
    "        output = self.i2o(combined)\n",
    "        #Soft max get tag\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "#Create Model\n",
    "rnn = RNN(n_chars, n_hidden, n_categories,False)\n",
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3747, -1.3851, -1.3765, -1.4092]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = charToTensor('今')\n",
    "hidden =torch.zeros(1, n_hidden)\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1, 2916])\n",
      "torch.Size([1, 128])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4016, -1.3726, -1.3761, -1.3951]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = lineToTensor('蔡英文今天發表演說')\n",
    "print(input.shape)\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "print(hidden.shape)\n",
    "print(input[0])\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(len(next_hidden[0]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 'society', 'business', 'sports']\n",
      "('society', 1)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "print(all_categories)\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = society / line = 毒販槍自抵太陽穴與警對峙1小時\n",
      "category = society / line = 土城鵝肉名店遭縱火1死4傷\n",
      "category = society / line = 刑事局前主秘╱許瑞山包庇賭場二審逆轉判3年4月\n",
      "category = politics / line = 行政契約協商若無結果林峯正：婦聯會資產將被凍結\n",
      "category = sports / line = 陽岱鋼談基層棒球：禮節比技術重要10倍\n",
      "category = sports / line = 勇士換戲碼「浪花兄弟」險翻船\n",
      "category = business / line = 義氣！侯貞雄捐錢捐鋼蓋台大社科院免冠名\n",
      "category = sports / line = 冬盟》首場無四死球完封朴峻杓暫居雙冠王\n",
      "category = politics / line = 民進黨布局2020英德配？清邁配？\n",
      "category = sports / line = 百敗翻身奪外卡最佳總教練落雙城\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Turn_input2tensor(category,line):\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = Turn_input2tensor(train_sampler[i][0],train_sampler[i][1])\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定Loss function－計算預測以及實際答案之間的差距\n",
    "## NLLoss <- Negative Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定參數(learning rate)以及訓練流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # If you set this too high, it might explode. If too low, it might not learn\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "def train(model,category_tensor, line_tensor,word_index,use_embedding):\n",
    "    hidden = model.initHidden()\n",
    "    model.zero_grad()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        if use_embedding:\n",
    "            output, hidden = model(word_index[i], hidden)\n",
    "        else:\n",
    "            output, hidden = model(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (i2h): Linear(in_features=3044, out_features=128, bias=True)\n",
      "  (i2o): Linear(in_features=3044, out_features=4, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "500 5% (0m 15s) 1.3346 冬季聯盟／投野兩小獅驗收秋訓成果 / sports ✓\n",
      "1000 11% (0m 30s) 1.3587 三星7奈米難產台積大吃高通訂單 / sports ✗ (business)\n",
      "1500 17% (0m 46s) 1.3709 「比特幣是黃金2.0」比特幣億萬富翁自估再漲20倍 / sports ✗ (business)\n",
      "2000 23% (1m 2s) 1.3663 同一地點／空姐才被潑糞又遭潑滾燙瀝青 / sports ✗ (society)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-43ed6942bb58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTurn_input2tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mword_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinetoindexTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-fa46ee3ea604>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, category_tensor, line_tensor, word_index, use_embedding)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Add parameters' gradients to their values, multiplied by learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch_teach\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch_teach\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "epochs = 3\n",
    "print_every = 500\n",
    "plot_every = 100\n",
    "step = 0\n",
    "n_steps = epochs*len(train_sampler)\n",
    "n_hidden = 128\n",
    "use_embedding = False\n",
    "\n",
    "\n",
    "model = RNN(n_chars, n_hidden, n_categories,use_embedding)\n",
    "print(model)\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i in range(0,len(train_sampler)):\n",
    "        category, line, category_tensor, line_tensor = Turn_input2tensor(train_sampler[i][0],train_sampler[i][1])\n",
    "        word_index = linetoindexTensor(train_sampler[i][1])\n",
    "        output, loss = train(model,category_tensor, line_tensor,word_index,use_embedding)\n",
    "        current_loss += loss\n",
    "        step+=1\n",
    "        # Print iter number, loss, name and guess\n",
    "        if step % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('%d %d%% (%s) %.4f %s / %s %s' % (step, step / n_steps * 100, timeSince(start), loss, line, guess, correct))\n",
    "        # Add current loss avg to list of losses\n",
    "        if step % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = len(valid_sampler)\n",
    "# Just return an output given a line\n",
    "hidden = model.initHidden()\n",
    "# print(model(torch.tensor([50]),hidden))\n",
    "def evaluate(model,line_tensor,word_index,use_embedding):\n",
    "    hidden = model.initHidden()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        if use_embedding:\n",
    "            output, hidden = model(word_index[i], hidden)\n",
    "        else:\n",
    "            output, hidden = model(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = Turn_input2tensor(valid_sampler[i][0],valid_sampler[i][1])\n",
    "    word_index = linetoindexTensor(valid_sampler[i][1])\n",
    "    output = evaluate(model,line_tensor,word_index,use_embedding)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "print(confusion)\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,line_tensor,word_index,use_embedding):\n",
    "    hidden = model.initHidden()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        if use_embedding:\n",
    "            output, hidden = model(word_index[i], hidden)\n",
    "        else:\n",
    "            output, hidden = model(line_tensor[i], hidden)\n",
    "    return output\n",
    "\n",
    "def predict(model,input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        word_index = linetoindexTensor(input_line)\n",
    "        output = evaluate(model,lineToTensor(input_line),word_index,True)\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "# predict(model,'Dovesky')\n",
    "# predict(model,'Jackson')\n",
    "# predict(model,'Satoshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch_teach\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"newsmodel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_model = torch.load('newsmodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> 參選2020\n",
      "(-0.75) business\n",
      "(-1.56) society\n",
      "(-1.60) sports\n",
      "\n",
      "> 女友跨年上男人車..醋男談判反挨刀\n",
      "(-0.95) society\n",
      "(-1.26) politics\n",
      "(-1.61) business\n"
     ]
    }
   ],
   "source": [
    "predict(news_model,'參選2020')\n",
    "predict(news_model,'女友跨年上男人車..醋男談判反挨刀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_teach",
   "language": "python",
   "name": "pytorch_teach"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
